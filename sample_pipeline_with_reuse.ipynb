{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading postgres module without psycopg2 installed. Will crash at runtime if postgres functionality is used.\n",
      "Loading S3 module without the python package boto3. Will crash at runtime if S3 functionality is used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to d6tflow!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import luigi\n",
    "import d6tflow\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base code to put in a package for reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class requires_instance(object):\n",
    "    \"\"\"\n",
    "    Modified version of luigi.util.requires, requiring instanced Tasks and ignoring inherits\n",
    "\n",
    "    TODO: Name this better!\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *tasks_to_require):\n",
    "        super().__init__()\n",
    "        if not tasks_to_require:\n",
    "            raise TypeError(\"tasks_to_require cannot be empty\")\n",
    "\n",
    "        self.tasks_to_require = tasks_to_require\n",
    "\n",
    "    def __call__(self, task_that_requires):\n",
    "        # task_that_requires = inherits(*self.tasks_to_require)(task_that_requires)\n",
    "\n",
    "        # Modify task_that_requires by adding requires method.\n",
    "        # If only one task is required, this single task is returned.\n",
    "        # Otherwise, list of tasks is returned\n",
    "        def requires(_self):\n",
    "            # Should this be returning based on _self?  I'm not sure the difference...\n",
    "            # Warning about using multiple requirements with d6tflow's inputLoad().  The logic looks for\n",
    "            # a tuple, else a dict, else treats as a single Task.  For now force non-single case to a tuple, but really\n",
    "            # the logic should be changed in d6tflow\n",
    "            return self.tasks_to_require[0] if len(self.tasks_to_require) == 1 else tuple(self.tasks_to_require)\n",
    "        task_that_requires.requires = requires\n",
    "\n",
    "        return task_that_requires\n",
    "\n",
    "\n",
    "class TaskMixin:\n",
    "    @classmethod\n",
    "    def make_subclass(cls, subclass_name=None, upstream_instances=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Returns a subclass of the base class,\n",
    "\n",
    "        :param subclass_name: Name of the subclass.  Default is the parent class's name with \"BaseTask\" stripped from\n",
    "                              its ends\n",
    "        :param requires_instance: If set, adds a @requires_instance decorator on the subclass which maps the subclass's\n",
    "                                  requires using INSTANCED Tasks (not Task classes like normal Luigi)\n",
    "        :param kwargs: Anything to be overwritten on the parent class.  This is passed as the third argument of the\n",
    "                       \"type\" function and can contain class variables and functions.  Suggested use:\n",
    "                            target_dir\n",
    "                            additional class parameters?\n",
    "\n",
    "        :return:\n",
    "            The subclass (not instantiated)\n",
    "        \"\"\"\n",
    "        subclass_name = subclass_name if subclass_name else cls.__name__.strip(\"BaseTask\")\n",
    "        subclass = type(subclass_name, (cls,), kwargs)\n",
    "        if upstream_instances:\n",
    "            # Make everything a list that we can expand into the below decorator\n",
    "            upstream_instances = make_iterable(upstream_instances)\n",
    "\n",
    "            subclass = requires_instance(*upstream_instances)(subclass)\n",
    "        return subclass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_iterable(arg):\n",
    "    \"\"\"\n",
    "    Returns whether an argument is an iterable but not a string\n",
    "    From stackoverflow: \"how to tell a varaiable is iterable but not a string\"\n",
    "    Args:\n",
    "        arg: some variable to be tested\n",
    "    Returns:\n",
    "        (bool)\n",
    "    \"\"\"\n",
    "    return (\n",
    "            isinstance(arg, collections.Iterable)\n",
    "            and not isinstance(arg, str)\n",
    "    )\n",
    "\n",
    "\n",
    "def make_iterable(arg):\n",
    "    \"\"\"\n",
    "    Makes arg into an iterable if it isn't already (note that strings are ignored and treated as non-iterable)\n",
    "    \"\"\"\n",
    "    return arg if is_iterable(arg) else (arg,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "Task output naming conventions:\n",
    "  * (output_dir)/(target_dir)/(task_id)-(persist_output_name).extension\n",
    "This schema is defined in d6tflow's TaskData._getpath() (a base class inherrited by all dt6flow Tasks), which sets the output paths for all Targets (outputs) of a Task\n",
    "output_dir: (added by d6tflow)\n",
    "  * a global output directory used by all Tasks in a pipeline in d6tflow.\n",
    "  * Set by: d6tflow.set_dir()\n",
    "target_dir: (added by d6tflow)\n",
    "  * Subdir used by a task\n",
    "  * Set by: cls.target_dir\n",
    "task_id: (from luigi.Task)\n",
    "  * Defined by luigi.Task.__init__() to be (task_namespace)_(task_params_as_kwargs)_(hash_of_params)\n",
    "  * Set by: indirectly (via namespace and kwargs)\n",
    "task_namespace: (from luigi.Task)\n",
    "  * Also mentioned as a task_family in luigi code.  namespace prefix on all output files.  Feels like it argues a bit with target_dir.  Defaults to cls.__name__\n",
    "  * luigi.Task.get_task_family() and luigi.Task.get_task_namespace() are the toolchain that use this\n",
    "  * set by: cls.task_namespace\n",
    "persist_output_name: (added by d6tflow)\n",
    "  * Naming convention used for outputs.  This defines the output naming used by the .save() function and the suffix on the output files\n",
    "  * default: cls.persist = ['data']  (single output named 'data')\n",
    "  * If only one output, the output routing functions (eg: load()) deliver it directly.  If a list, load() loads a list of the data.  (Can it handle named references using dicts too?)\n",
    "  * When .save()ing data in a Task, use a dict like: self.save({'output1': df_to_save1, 'output2': df_to_save2})\n",
    "  * set by: cls.persist\n",
    "\n",
    "Possible workflows:\n",
    "  -   Use classmethod that subclasses and names the subclass/target_dir to keep things identifiable\n",
    "  -   have an initialization constructor rather than subclassing constructor\n",
    "      -   This CANNOT use task_namespace from luigi.Task directly as it's init() statically defines task_id based on\n",
    "          task_namespace at init() time.  task_namespace must be defined on the CLASS rather than instance because\n",
    "          it is gotten by a class methods (get_task_namespace).  I THINK target_dir would work without subclassing\n",
    "          but haven't tested fully\n",
    "      -   We could override some of these methods and then avoid needing to subclass things.\n",
    "      -   If we do a different workflow than subclassing we'd need something like:\n",
    "              my_instance = requires_decorator(upstream_task_instance)(MyClass.\\[SOMEHOW APPLY NAMESPACE/DIR AND RETURN CLS\\])(instance kwargs)\n",
    "  -   In both cases, I can instance ahead of time (for parameter setting) and use @requires_instance to add\n",
    "      requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of reusable Task classes\n",
    "(these are what we'd define in a package for reusing to build a pipeline from)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper for fake data...\n",
    "DATA_VALUES = [1, 2, 3]\n",
    "\n",
    "class BaseTaskGetTwoData(TaskMixin, d6tflow.tasks.TaskPqPandas):\n",
    "    \"\"\"\n",
    "    This is a fake 'data generation' task that creates two dataframes with a little data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define parameters as luigi.Parameter subclasses.  Luigi looks for these if you ever use inherrits(), and I think\n",
    "    # also checks to make sure they're defined early in a pipeline run?\n",
    "    columns = luigi.ListParameter(default=['a', 'b', 'c'])\n",
    "\n",
    "    # Set persist to explicitly name the outputs of a process and/or define more than one\n",
    "    # persist = ['data']  # Default set internally\n",
    "    persist = ['output1', 'output2']\n",
    "\n",
    "    def run(self):\n",
    "        # Fabricate some data\n",
    "        df = pd.DataFrame([{k: v*i_k for i_k, k in enumerate(self.columns)} for v in DATA_VALUES])\n",
    "\n",
    "        to_save = {output_name: df for output_name in self.persist}\n",
    "        self.save(to_save)\n",
    "\n",
    "\n",
    "class BaseTaskGetOneData(TaskMixin, d6tflow.tasks.TaskPqPandas):\n",
    "    \"\"\"\n",
    "    This is a fake 'data generation' task that creates one dataframe with a little data\n",
    "    \"\"\"\n",
    "    columns = luigi.ListParameter(default=['a', 'b', 'c'])\n",
    "\n",
    "    def run(self):\n",
    "        # Fabricate some data\n",
    "        df = pd.DataFrame([{k: v*i_k for i_k, k in enumerate(self.columns)} for v in DATA_VALUES])\n",
    "\n",
    "        self.save(df)\n",
    "\n",
    "\n",
    "class BaseTaskPrintDf(TaskMixin, d6tflow.tasks.TaskCache):\n",
    "    \"\"\"\n",
    "    This task prints one or more dataframes to the screen\n",
    "    \"\"\"\n",
    "    def run(self):\n",
    "        # Basic Luigi: .input() returns whatever self.requires() returns, so to use input() you need to interpret\n",
    "        # whatever comes from upstream (could be a Target, Tuple(Target1, ...), Tuple(Dict('name1': Target1, ...), ...)\n",
    "        # dfs = self.input().load()  # For a single input.  self.input() returns a Target, which has a .load()\n",
    "        # For loading all of multiple inputs (can also do key's here I think?).  Note it always flattens to a list.\n",
    "        # This function could be improved to reflect the structure of whatever is in requires() better\n",
    "        dfs = self.inputLoad()\n",
    "\n",
    "        # Do some \"work\"\n",
    "        print(\"Printing results:\")\n",
    "        for i, df in enumerate(dfs):\n",
    "            print(f\"df {i}\")\n",
    "            print(df)\n",
    "\n",
    "\n",
    "class BaseTaskDropColumn(TaskMixin, d6tflow.tasks.TaskPqPandas):\n",
    "    \"\"\"\n",
    "    Drop a column from a dataframe, saving the resulting dataframe for future tasks\n",
    "    \"\"\"\n",
    "    column = luigi.Parameter()\n",
    "\n",
    "    def run(self):\n",
    "        df = self.input().load()\n",
    "\n",
    "        df = df.drop(columns=[self.column])\n",
    "        self.save(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/schematic_of_pipeline.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scribs/code_git_backed/d6tflow-recipes/venv/lib/python3.7/site-packages/ipykernel_launcher.py:11: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# Example of defining output by making a Subclass and then instantiating it\n",
    "# Subclassing gives us control over the target_dir.  Everything from the same subclass goes to the same target_dir, so\n",
    "# each Task (atomic action in a pipeline) needs its own subclass of a Task\n",
    "TaskGetTwoData = BaseTaskGetTwoData.make_subclass(subclass_name=\"MyGetTwoData\", target_dir='my_get_two_data')\n",
    "my_get_two_data = TaskGetTwoData(columns=['a', 'b', 'c'])\n",
    "\n",
    "# We can also do it all in one command\n",
    "my_get_two_data2 = BaseTaskGetTwoData.make_subclass(subclass_name=\"MyGetTwoData2\",\n",
    "                                                    target_dir='my_get_two_data2',)(columns=['d', 'e', 'f'])\n",
    "\n",
    "my_get_one_data = BaseTaskGetOneData.make_subclass(subclass_name=\"MyGetOneData\",\n",
    "                                                   target_dir='my_get_one_data')(columns=['aa', 'bb'])\n",
    "\n",
    "# Downstream tasks can consume upstream, fully instantiated tasks\n",
    "my_drop_column = BaseTaskDropColumn.make_subclass(subclass_name=\"MyDropColumn\", \n",
    "                                                  target_dir=\"my_drop_column\", \n",
    "                                                  upstream_instances=[my_get_one_data])(column='aa')\n",
    "\n",
    "my_print_df_1 = BaseTaskPrintDf.make_subclass(subclass_name=\"MyPrintDf1\", upstream_instances=my_drop_column)()\n",
    "\n",
    "# We can also map multiple inputs to a single task\n",
    "# (target_dir doesn't matter here - no output!)\n",
    "my_print_df_2 = BaseTaskPrintDf.make_subclass(upstream_instances=[\n",
    "                                                                  my_get_two_data,\n",
    "                                                                  my_get_two_data2,\n",
    "                                                                  my_drop_column,\n",
    "                                                                  ],\n",
    "                                              target_dir='this_doesnt_matter_but')()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This runs everything it needs because nothing is pre-computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Informed scheduler that task   MyPrintDf1__99914b932b   has status   PENDING\n",
      "INFO: Informed scheduler that task   MyDropColumn_aa_8d8cf8322c   has status   DONE\n",
      "INFO: Done scheduling tasks\n",
      "INFO: Running Worker with 1 processes\n",
      "INFO: [pid 20463] Worker Worker(salt=174418553, workers=1, host=scribs-desktop, username=scribs, pid=20463) running   MyPrintDf1()\n",
      "INFO: [pid 20463] Worker Worker(salt=174418553, workers=1, host=scribs-desktop, username=scribs, pid=20463) done      MyPrintDf1()\n",
      "INFO: Informed scheduler that task   MyPrintDf1__99914b932b   has status   DONE\n",
      "INFO: Worker Worker(salt=174418553, workers=1, host=scribs-desktop, username=scribs, pid=20463) was stopped. Shutting down Keep-Alive thread\n",
      "INFO: \n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "Scheduled 2 tasks of which:\n",
      "* 1 complete ones were encountered:\n",
      "    - 1 MyDropColumn(column=aa)\n",
      "* 1 ran successfully:\n",
      "    - 1 MyPrintDf1()\n",
      "\n",
      "This progress looks :) because there were no failed tasks or missing dependencies\n",
      "\n",
      "===== Luigi Execution Summary =====\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing results:\n",
      "df 0\n",
      "bb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .run() is supposed to support multiple tasks but it wasn't working.  We run once for each (could also have a single\n",
    "# aggregation task that requires all the above tasks)\n",
    "d6tflow.run(my_print_df_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This only runs what didn't run above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Informed scheduler that task   PrintDf__99914b932b   has status   PENDING\n",
      "INFO: Informed scheduler that task   MyDropColumn_aa_8d8cf8322c   has status   DONE\n",
      "INFO: Informed scheduler that task   MyGetTwoData2___d____e____f___a0fcbe71f2   has status   DONE\n",
      "INFO: Informed scheduler that task   MyGetTwoData___a____b____c___bc7315d43a   has status   DONE\n",
      "INFO: Done scheduling tasks\n",
      "INFO: Running Worker with 1 processes\n",
      "INFO: [pid 20463] Worker Worker(salt=538919802, workers=1, host=scribs-desktop, username=scribs, pid=20463) running   PrintDf()\n",
      "INFO: [pid 20463] Worker Worker(salt=538919802, workers=1, host=scribs-desktop, username=scribs, pid=20463) done      PrintDf()\n",
      "INFO: Informed scheduler that task   PrintDf__99914b932b   has status   DONE\n",
      "INFO: Worker Worker(salt=538919802, workers=1, host=scribs-desktop, username=scribs, pid=20463) was stopped. Shutting down Keep-Alive thread\n",
      "INFO: \n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "Scheduled 4 tasks of which:\n",
      "* 3 complete ones were encountered:\n",
      "    - 1 MyDropColumn(column=aa)\n",
      "    - 1 MyGetTwoData(columns=[\"a\", \"b\", \"c\"])\n",
      "    - 1 MyGetTwoData2(columns=[\"d\", \"e\", \"f\"])\n",
      "* 1 ran successfully:\n",
      "    - 1 PrintDf()\n",
      "\n",
      "This progress looks :) because there were no failed tasks or missing dependencies\n",
      "\n",
      "===== Luigi Execution Summary =====\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing results:\n",
      "df 0\n",
      "   a  b  c\n",
      "0  0  1  2\n",
      "1  0  2  4\n",
      "2  0  3  6\n",
      "df 1\n",
      "   a  b  c\n",
      "0  0  1  2\n",
      "1  0  2  4\n",
      "2  0  3  6\n",
      "df 2\n",
      "   d  e  f\n",
      "0  0  1  2\n",
      "1  0  2  4\n",
      "2  0  3  6\n",
      "df 3\n",
      "   d  e  f\n",
      "0  0  1  2\n",
      "1  0  2  4\n",
      "2  0  3  6\n",
      "df 4\n",
      "bb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d6tflow.run(my_print_df_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can see the results for these cached in the data directory\n",
    "\n",
    "There is a directory for each pipeline step (defined by target_dir) and the filenames depend on the schema described in notes above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:\n",
      "total 16\n",
      "drwxr-xr-x 2 scribs scribs 4096 Apr 30 14:00 my_drop_column\n",
      "drwxr-xr-x 2 scribs scribs 4096 Apr 30 14:00 my_get_one_data\n",
      "drwxr-xr-x 2 scribs scribs 4096 Apr 30 14:00 my_get_two_data\n",
      "drwxr-xr-x 2 scribs scribs 4096 Apr 30 14:00 my_get_two_data2\n",
      "\n",
      "data/my_drop_column:\n",
      "total 4\n",
      "-rw-r--r-- 1 scribs scribs 1685 Apr 30 14:00 MyDropColumn_aa_8d8cf8322c-data.parquet\n",
      "\n",
      "data/my_get_one_data:\n",
      "total 4\n",
      "-rw-r--r-- 1 scribs scribs 2317 Apr 30 14:00 MyGetOneData___aa____bb___24e1609319-data.parquet\n",
      "\n",
      "data/my_get_two_data:\n",
      "total 8\n",
      "-rw-r--r-- 1 scribs scribs 2928 Apr 30 14:00 MyGetTwoData___a____b____c___bc7315d43a-output1.parquet\n",
      "-rw-r--r-- 1 scribs scribs 2928 Apr 30 14:00 MyGetTwoData___a____b____c___bc7315d43a-output2.parquet\n",
      "\n",
      "data/my_get_two_data2:\n",
      "total 8\n",
      "-rw-r--r-- 1 scribs scribs 2928 Apr 30 14:00 MyGetTwoData2___d____e____f___a0fcbe71f2-output1.parquet\n",
      "-rw-r--r-- 1 scribs scribs 2928 Apr 30 14:00 MyGetTwoData2___d____e____f___a0fcbe71f2-output2.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls -lR data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And reusing parts (or all) of the above pipeline.  We see here they don't run a second time (except the prints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Informed scheduler that task   MyPrintDf1__99914b932b   has status   PENDING\n",
      "INFO: Informed scheduler that task   MyDropColumn_aa_8d8cf8322c   has status   DONE\n",
      "INFO: Done scheduling tasks\n",
      "INFO: Running Worker with 1 processes\n",
      "INFO: [pid 20463] Worker Worker(salt=675251088, workers=1, host=scribs-desktop, username=scribs, pid=20463) running   MyPrintDf1()\n",
      "INFO: [pid 20463] Worker Worker(salt=675251088, workers=1, host=scribs-desktop, username=scribs, pid=20463) done      MyPrintDf1()\n",
      "INFO: Informed scheduler that task   MyPrintDf1__99914b932b   has status   DONE\n",
      "INFO: Worker Worker(salt=675251088, workers=1, host=scribs-desktop, username=scribs, pid=20463) was stopped. Shutting down Keep-Alive thread\n",
      "INFO: \n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "Scheduled 2 tasks of which:\n",
      "* 1 complete ones were encountered:\n",
      "    - 1 MyDropColumn(column=aa)\n",
      "* 1 ran successfully:\n",
      "    - 1 MyPrintDf1()\n",
      "\n",
      "This progress looks :) because there were no failed tasks or missing dependencies\n",
      "\n",
      "===== Luigi Execution Summary =====\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing results:\n",
      "df 0\n",
      "bb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d6tflow.run(my_print_df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Informed scheduler that task   PrintDf__99914b932b   has status   PENDING\n",
      "INFO: Informed scheduler that task   MyDropColumn_aa_8d8cf8322c   has status   DONE\n",
      "INFO: Informed scheduler that task   MyGetTwoData2___d____e____f___a0fcbe71f2   has status   DONE\n",
      "INFO: Informed scheduler that task   MyGetTwoData___a____b____c___bc7315d43a   has status   DONE\n",
      "INFO: Done scheduling tasks\n",
      "INFO: Running Worker with 1 processes\n",
      "INFO: [pid 20463] Worker Worker(salt=136766269, workers=1, host=scribs-desktop, username=scribs, pid=20463) running   PrintDf()\n",
      "INFO: [pid 20463] Worker Worker(salt=136766269, workers=1, host=scribs-desktop, username=scribs, pid=20463) done      PrintDf()\n",
      "INFO: Informed scheduler that task   PrintDf__99914b932b   has status   DONE\n",
      "INFO: Worker Worker(salt=136766269, workers=1, host=scribs-desktop, username=scribs, pid=20463) was stopped. Shutting down Keep-Alive thread\n",
      "INFO: \n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "Scheduled 4 tasks of which:\n",
      "* 3 complete ones were encountered:\n",
      "    - 1 MyDropColumn(column=aa)\n",
      "    - 1 MyGetTwoData(columns=[\"a\", \"b\", \"c\"])\n",
      "    - 1 MyGetTwoData2(columns=[\"d\", \"e\", \"f\"])\n",
      "* 1 ran successfully:\n",
      "    - 1 PrintDf()\n",
      "\n",
      "This progress looks :) because there were no failed tasks or missing dependencies\n",
      "\n",
      "===== Luigi Execution Summary =====\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing results:\n",
      "df 0\n",
      "   a  b  c\n",
      "0  0  1  2\n",
      "1  0  2  4\n",
      "2  0  3  6\n",
      "df 1\n",
      "   a  b  c\n",
      "0  0  1  2\n",
      "1  0  2  4\n",
      "2  0  3  6\n",
      "df 2\n",
      "   d  e  f\n",
      "0  0  1  2\n",
      "1  0  2  4\n",
      "2  0  3  6\n",
      "df 3\n",
      "   d  e  f\n",
      "0  0  1  2\n",
      "1  0  2  4\n",
      "2  0  3  6\n",
      "df 4\n",
      "bb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d6tflow.run(my_print_df_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d6tflow-recipes-using-fork",
   "language": "python",
   "name": "d6tflow-recipes-using-fork"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
